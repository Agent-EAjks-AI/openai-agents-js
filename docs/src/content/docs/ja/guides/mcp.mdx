---
title: MCP 連携
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import hostedConnectorExample from '../../../../../../examples/docs/mcp/hostedConnector.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';
import toolFilterExample from '../../../../../../examples/docs/mcp/tool-filter.ts?raw';

The [**Model Context Protocol (MCP)**](https://modelcontextprotocol.io) は、アプリケーションが LLM にツールとコンテキストを提供する方法を標準化するオープンプロトコルです。MCP のドキュメントより:

> MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.

この SDK がサポートする MCP サーバーは 3 種類あります:

1. **リモート MCP サーバーツール** – [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp) がツールとして利用するリモート MCP サーバー
2. **Streamable HTTP MCP サーバー** – [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http) を実装したローカルまたはリモートのサーバー
3. **Stdio MCP サーバー** – 標準入出力経由でアクセスするサーバー（最もシンプルな選択肢）

ユースケースに応じてサーバー種別を選択してください:

| 必要なこと                                                                     | 推奨オプション             |
| ------------------------------------------------------------------------------ | -------------------------- |
| 公開アクセス可能なリモートサーバーをデフォルトの OpenAI responses モデルで呼ぶ | **1. リモート MCP ツール** |
| 公開アクセス可能なリモートサーバーを使うが、ツール呼び出しはローカルでトリガー | **2. Streamable HTTP**     |
| ローカルで稼働する Streamable HTTP サーバーを使う                              | **2. Streamable HTTP**     |
| 非 OpenAI-Responses モデルで任意の Streamable HTTP サーバーを使う              | **2. Streamable HTTP**     |
| 標準 I/O プロトコルのみ対応のローカル MCP サーバーを扱う                       | **3. Stdio**               |

## 1. Hosted MCP server tools

組み込みツール（Hosted）は、やり取り全体をモデル側に押し込みます。あなたのコードが MCP サーバーを呼ぶ代わりに、OpenAI Responses API がリモートのツールエンドポイントを呼び出し、その結果をモデルへストリーミングします。

以下は hosted MCP ツールを使う最も簡単な例です。`hostedMcpTool` ユーティリティ関数にリモート MCP サーバーのラベルと URL を渡すことで、hosted MCP サーバーツールを作成できます。

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

次に、`run` 関数（またはカスタマイズした `Runner` インスタンスの `run` メソッド）でエージェントを実行できます:

<Code lang="typescript" code={hostedExample} title="Hosted MCP ツールで実行" />

増分的な MCP の結果をストリーミングするには、`Agent` を実行するときに `stream: true` を渡します:

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="Hosted MCP ツールで実行（ストリーミング）"
/>

#### 任意の承認フロー

センシティブな操作では、個々のツール呼び出しに対して人間の承認を必須にできます。`requireApproval: 'always'` または、ツール名を `'never'`/`'always'` に対応付ける詳細なオブジェクトを渡してください。

ツール呼び出しの安全性をプログラムで判定できる場合は、[`onApproval` コールバック](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts) を使って承認または拒否できます。人による承認が必要な場合は、ローカルの関数ツールと同様に `interruptions` を使う同じ [人間の介入（HITL）のアプローチ](/openai-agents-js/ja/guides/human-in-the-loop/)を利用できます。

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="Hosted MCP ツールでの Human in the loop"
/>

### コネクタ対応の Hosted サーバー

Hosted MCP は OpenAI コネクタにも対応しています。`serverUrl` を提供する代わりに、コネクタの `connectorId` と `authorization` トークンを渡します。Responses API が認証を処理し、Hosted MCP インターフェース経由でコネクタのツールを公開します。

<Code
  lang="typescript"
  code={hostedConnectorExample}
  title="コネクタ対応の Hosted MCP ツール"
/>

この例では、環境変数 `GOOGLE_CALENDAR_AUTHORIZATION` に Google OAuth Playground から取得した OAuth トークンを保持し、コネクタ対応サーバーが Calendar API を呼び出せるように認可します。ストリーミングもあわせて実演する実行可能サンプルは [`examples/connectors`](https://github.com/openai/openai-agents-js/tree/main/examples/connectors) を参照してください。

完全な動作サンプル（Hosted ツール/Streamable HTTP/stdio + ストリーミング、HITL、onApproval）は GitHub リポジトリの [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) にあります。

## 2. Streamable HTTP MCP サーバー

エージェントがローカルまたはリモートの Streamable HTTP MCP サーバーと直接やり取りする場合は、サーバーの `url`、`name`、オプション設定を指定して `MCPServerStreamableHttp` をインスタンス化します:

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="Streamable HTTP MCP サーバーで実行"
/>

コンストラクタは、`authProvider`、`requestInit`、`fetch`、`reconnectionOptions`、`sessionId` などの MCP TypeScript SDK の追加オプションも受け付けます。詳細は [MCP TypeScript SDK リポジトリ](https://github.com/modelcontextprotocol/typescript-sdk)とそのドキュメントを参照してください。

## 3. Stdio MCP サーバー

標準 I/O のみを公開するサーバーには、`fullCommand` を指定して `MCPServerStdio` をインスタンス化します:

<Code lang="typescript" code={stdioExample} title="Stdio MCP サーバーで実行" />

## 知っておくべきこと

**Streamable HTTP** と **Stdio** のサーバーでは、`Agent` の実行ごとに利用可能なツールを見つけるため `list_tools()` を呼び出す場合があります。この往復は遅延を増やす可能性があり（特にリモートサーバーで）、`MCPServerStdio` または `MCPServerStreamableHttp` に `cacheToolsList: true` を渡すことでメモリキャッシュできます。

ツール一覧が変わらないと確信できる場合にのみ有効化してください。後でキャッシュを無効化するには、サーバーインスタンスで `invalidateToolsCache()` を呼び出します。

### ツールのフィルタリング

`createMCPToolStaticFilter` による静的フィルター、またはカスタム関数を渡すことで、各サーバーから公開するツールを制限できます。以下は両アプローチを示す併用例です:

<Code
  lang="typescript"
  code={toolFilterExample}
  title="ツールのフィルタリング"
/>

## 参考資料

- [Model Context Protocol](https://modelcontextprotocol.io/) – 公式仕様
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) – 上記で参照した実行可能デモ
